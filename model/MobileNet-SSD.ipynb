{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def load_dataset(dataset_dir):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(dataset_dir, filename)\n",
    "            annotation_path = os.path.join(dataset_dir, filename[:-4] + '.xml')\n",
    "            images.append(image_path)\n",
    "            annotations.append(annotation_path)\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0  # Normalisasi nilai piksel menjadi [0, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotation(annotation_path, target_size):\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "    boxes = []\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        box = obj.find('bndbox')\n",
    "        xmin = int(box.find('xmin').text)\n",
    "        ymin = int(box.find('ymin').text)\n",
    "        xmax = int(box.find('xmax').text)\n",
    "        ymax = int(box.find('ymax').text)\n",
    "\n",
    "        # Ubah koordinat kotak pembatas sesuai dengan ukuran gambar yang diubah\n",
    "        xmin = xmin * target_size[1] / original_width\n",
    "        ymin = ymin * target_size[0] / original_height\n",
    "        xmax = xmax * target_size[1] / original_width\n",
    "        ymax = ymax * target_size[0] / original_height\n",
    "\n",
    "        boxes.append([xmin, ymin, xmax, ymax, label])\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_tf_example(image_path, annotation_path, target_size):\n",
    "    image = preprocess_image(image_path, target_size)\n",
    "    boxes = process_annotation(annotation_path, target_size)\n",
    "\n",
    "    feature = {\n",
    "        'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image.tobytes()])),\n",
    "        'xmin': tf.train.Feature(float_list=tf.train.FloatList(value=[box[0] for box in boxes])),\n",
    "        'ymin': tf.train.Feature(float_list=tf.train.FloatList(value=[box[1] for box in boxes])),\n",
    "        'xmax': tf.train.Feature(float_list=tf.train.FloatList(value=[box[2] for box in boxes])),\n",
    "        'ymax': tf.train.Feature(float_list=tf.train.FloatList(value=[box[3] for box in boxes])),\n",
    "        'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[box[4].encode() for box in boxes]))\n",
    "    }\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisikan konfigurasi model seperti jumlah kelas dan ukuran gambar input\n",
    "num_classes = 1\n",
    "input_size = (300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n\u001b[0;32m      7\u001b[0m \u001b[39m# Load dataset\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m train_images, train_annotations \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39;49m\u001b[39mtrain/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m test_images, test_annotations \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39m\u001b[39mtest/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39m# Create and compile the model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 8\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(dataset_dir)\u001b[0m\n\u001b[0;32m      6\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m annotations \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(dataset_dir):\n\u001b[0;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     10\u001b[0m         image_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dataset_dir, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'train/'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "train_images, train_annotations = load_dataset('train/')\n",
    "test_images, test_annotations = load_dataset('test/')\n",
    "\n",
    "# Create and compile the model\n",
    "num_classes = 2\n",
    "input_size = (300, 300)\n",
    "base_model = MobileNetV2(input_shape=input_size + (3,), include_top=False, weights='imagenet')\n",
    "x = Flatten()(base_model.output)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Preprocess data and create TFRecords\n",
    "# ...\n",
    "\n",
    "# Load TFRecords and train the model\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Convert training annotations to class indices\n",
    "train_labels = []\n",
    "for annotation_path in train_annotations:\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        label_idx = 0 if label == 'melon' else 1  # Assuming 'melon' is the first class and 'background' is the second class\n",
    "        train_labels.append(label_idx)\n",
    "\n",
    "# Convert test annotations to class indices\n",
    "test_labels = []\n",
    "for annotation_path in test_annotations:\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        label_idx = 0 if label == 'melon' else 1  # Assuming 'melon' is the first class and 'background' is the second class\n",
    "        test_labels.append(label_idx)\n",
    "\n",
    "# Create input pipeline for training data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.map(parse_function).shuffle(buffer_size=1000).batch(batch_size).repeat()\n",
    "\n",
    "# Create input pipeline for test data\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = test_dataset.map(parse_function).batch(batch_size)\n",
    "\n",
    "# Define the parse_function to load and preprocess images and labels\n",
    "def parse_function(image_path, label):\n",
    "    image = preprocess_image(image_path, input_size)\n",
    "    return image, label\n",
    "\n",
    "# Train the model\n",
    "steps_per_epoch = len(train_images) // batch_size\n",
    "validation_steps = len(test_images) // batch_size\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_dataset,\n",
    "    validation_steps=validation_steps\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
